{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "# Faces recognition example using eigenfaces and SVMs\n",
    "\n",
    "\n",
    "The dataset used in this example is a preprocessed excerpt of the\n",
    "\"Labeled Faces in the Wild\", aka LFW_:\n",
    "\n",
    "  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)\n",
    "\n",
    ".. _LFW: http://vis-www.cs.umass.edu/lfw/\n",
    "\n",
    "Expected results for the top 5 most represented people in the dataset:\n",
    "\n",
    "================== ============ ======= ========== =======\n",
    "                   precision    recall  f1-score   support\n",
    "================== ============ ======= ========== =======\n",
    "     Ariel Sharon       0.67      0.92      0.77        13\n",
    "     Colin Powell       0.75      0.78      0.76        60\n",
    "  Donald Rumsfeld       0.78      0.67      0.72        27\n",
    "    George W Bush       0.86      0.86      0.86       146\n",
    "Gerhard Schroeder       0.76      0.76      0.76        25\n",
    "      Hugo Chavez       0.67      0.67      0.67        15\n",
    "       Tony Blair       0.81      0.69      0.75        36\n",
    "\n",
    "      avg / total       0.80      0.80      0.80       322\n",
    "================== ============ ======= ========== =======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#Yuri Carlos Bonifácio Neves - 1609670\n",
    "\n",
    "# Projeto 03 - Reconhecimento de Faces para a disciplina de Reconhecimento de Padrões em Imagens (2017/1)\n",
    "\n",
    "#\n",
    "#   O presente trabalho procura classificar as faces de identidades famosas\n",
    "#por meio de eigen faces, tendo suas dimensionalidades reduzidas a partir\n",
    "#do algoritmo PCA e, posteriormente, classificadas utilizando 5 classificadores,\n",
    "#sendo eles:\n",
    "#   DecisionTree, Knn, Naive Bayes, LDA e SVM\n",
    "#\n",
    "#   Primeiramente é executado uma otimização na escolha dos parâmetros para cada um \n",
    "#dos classificadores por meio do GridSearchCv. As melhores escolhas são usadas no \n",
    "#processo de treino e classificação, e estão discriminadas a baixo \n",
    "#   Após este processo, é executado o PCA, a fim de reduzir a dimensionalidade das\n",
    "#eigenFaces.\n",
    "#   Como os classificadores são diferentes e possuem características de funcionamento\n",
    "#diferentes é executado uma busca a fim de encontrar qual o melhor número de \n",
    "#componentes para cada um destes classificadores. Os valores selecionados foram:\n",
    "\n",
    "#   DecisionTree - 45\n",
    "#   Naive Bayes  - 75\n",
    "#   Knn          - 65\n",
    "#   LDA          - 80\n",
    "#   SVM          - 80\n",
    "\n",
    "#   Então é feita a classificação com cada um dos classificadores com os parâmetros\n",
    "#e valores de componentes obitidos.\n",
    "\n",
    "#   Foi usada uma divisão de 75% dos dados para treino e 25% para teste.\n",
    "\n",
    "#   O Decision Tree foi o classificador com o pior resultado, como já era de se esperar,\n",
    "#uma vez que os dados são pouco categóricos. Seus resultados médios foram:\n",
    "#                  precision    recall      f1         support\n",
    "#                  0.53         0.52        0.52       322\n",
    "\n",
    "#   No Naive Bayes, por não possuir uma grande quantidade de parâmetros, a fim de \n",
    "#otimizar os resultados, foi definido como prior as proporções de cada classe,\n",
    "#ou seja, razão entre a quantidade de amostras que uma classe possuia e a quantidade\n",
    "#de amostras total. Aparentemente a definição de priors dessa maneira não foi\n",
    "#muito eficiente, já que não influenciou muito nos resultados.\n",
    "\n",
    "#Antes de se definir as priors\n",
    "#                 precision    recall      f1         support\n",
    "#                 0.78         0.77        0.76       322\n",
    "\n",
    "#Depois de se definir as priors\n",
    "#                 precision    recall      f1         support\n",
    "#                 0.77         0.75        0.75       322\n",
    "\n",
    "#   O Knn seguiu com resultados não muito bons. Suspeito que seja devido ao número\n",
    "#de amostras. possivelmente, se tivessemos mais amostras o Knn teria um melhor \n",
    "#desempenho. Segue os resultados:\n",
    "\n",
    "#                 precision    recall      f1         support\n",
    "#                 0.72         0.72        0.71       322\n",
    "\n",
    "#   LDA teve resultados muito bons, bem próximos do SVM. Infelizmente, mesmo após \n",
    "#o processo do LDA, as classes ainda ficam meio misturadas, provavel que por este\n",
    "#motivo os resultados não sejam melhores.\n",
    "#   Em termos de carga computacional, por sua proximidade de resultados com o SVM,\n",
    "#pode ser uma boa opção escolher usar o LDA em uma aplicação como essa em vez \n",
    "#do SVM.\n",
    "\n",
    "#                 precision    recall      f1         support\n",
    "#                 0.80         0.80        0.80       322\n",
    "\n",
    "#   O SVM obteve os melhores resultados, sendo eles:\n",
    "\n",
    "#                 precision    recall      f1         support\n",
    "#                 0.87         0.86        0.86       322\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "#vetor de classificadores\n",
    "clfss = []\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Download the data, if not already on disk and load it as numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-29 10:09:01,536 Loading LFW people faces from /home/yuricarlos/scikit_learn_data/lfw_home\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Split into a training set and a test set using a stratified k fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split into a training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.255s\n"
     ]
    }
   ],
   "source": [
    "n_components = 100\n",
    "\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled\n",
    "dataset): unsupervised feature extraction / dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 100 eigenfaces from 966 faces\n",
      "done in 0.233s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.027s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f8e2a9a7dd0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEOCAYAAACJlmBtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3XecXFX9//HXOySEmkJLgIABAiGUBBKaYgANEhHRryAl\nqKCiFLE8YoEvihDkqwIqoDRRwEKJKCg/kBKa0usGaYmhhRJCAoGYRFJIsp/fH+cOe3fY3ezOzuzs\nzL6fj8d9zC1nZj53A/cz95xzz1FEYGZm1qvaAZiZWffghGBmZoATgpmZZZwQzMwMcEIwM7OME4KZ\nmQFOCGZmlnFCMDMzAHpXOwBLJK0PjAdeApZWNxozqzNrAEOBKRHxVmuFnBC6j/HAVdUOwszq2ueA\nq1s76ITQfbwEcOWVVzJixIgqh1IZEydO5Nxzz612GBVV7+dY7+cH7T/H5cth3ry0vPlm02thvbDM\nn1/e+Pr0gYED07LeejBgQFovfi2s9+sHM2ZM5/Of/zxk15nWOCF0H0sBRowYwejRo6sdS0X079+/\nbs+toN7Psd7PD9I5brnlaGbNglmz4LXXml5few1mz06vb75Zzu+EQYOaLxttlF433LBp34Ybpgu8\n1LHP79XUWtxmdbQTgpn1KP/9L7zyCrz6atPrq6/yXgJ47rn067qzeveGwYNh443TUlgfPLj5+qBB\nsMYanf++cnBCMLO6EQFvvAEvv/z+5ZVX0tLZKpzevWGTTd6/FC78hWX99Zv9Mq8JTghmVjMiUr38\nzJlNy0svpaVw4V+ypPTPX2utVB2zxx4wZAhsuilstll6LSwbblh7F/r2ckKwLjNhwoRqh1Bx9X6O\nXXF+S5emC/wLL8CLLzYthQTw3/+W9rm9e6eL/Ac+AJtvni70xcuAAfCnP02gzv8ZWyVPkNM9SBoN\nNDQ0NNR9o53ZwoXw/PNpeeGFptcXXkgNtqVcltZcM13shw5Nywc+0HwZPBhWW63cZ1Ibpk6dypgx\nYwDGRMTU1sr5DsHMKmLx4nShf/bZpuW559K+N97o+Of16ZMu9Fts0fRaWIYOTVU5He19Y805IZhZ\nyVauTA21M2Y0LYWL/6uvdvzz1l8fttqqadlyy/S6xRap4ban/sLvKk4IZrZKS5aki/20afDvfzct\nzz4Ly5Z17LM23hi23jotW20Fw4Y1XfwHDKhM/NY+Tghm9p5ly9KF/umn0/LMMykJvPhix+r1Bw6E\nbbaB4cPT69Zbp9dhw2CddSoXv3WOE4JZDxSRnrh94gl48smmZcYMWLGifZ/Rp0/6Zb/ttunCX1i2\n2QY22KCy8VtlOCGY1bkVK2D6dPjXv5qWJ56At1od87K5tdeG7bZLy4gRadl221Sv36dPZWO3ruWE\nYFZHli6Fp56CqVPT8vjj6Zd/e+r5+/RJF/qRI2HHHWGHHWD77VOf/Xp9EMuac0Iwq1FLl6Zf+g0N\nTcszz7SvymfwYBg1Ki077phehw+H1VevfNzWfTkhmNWAlStTtc9DD8Ejj8Bjj6U7gVVd/KXUoLvz\nzk3LqFFpQDWzYk4IZt3QW2/Bgw+mBPDgg/Doo7BoUdvv6dUr1fOPGZMu/GPGpIv/uut2TcxW+5wQ\nzKosInX1vP9+eOCBtMyY0fZ7evVKjbu77JKWwsV/rbW6JmarT04IZl1s+fJU33/vvXDffSkRrKrH\nz6abphE4d989LaNHuz+/lZ8TglmFvftuqvf/5z/h7rvTHcDixa2X79Mn/eL/4AfhQx9qGorZrNKc\nEMzKbOXK1OXzrrvgzjvTXUBbY/Svtx7suWfTMmZMGrnTrKs5IZiVwUsvwW23peWuu9qelWvIENh7\nbxg7Ni3bbut+/tY9OCGYlWDJklT9c8stMGVK243Am24KH/0ofOQjsM8+aahmD9Ns3ZETglk7zZyZ\nEsDNN6e7gNaqgQYOTAlg331h3Lg0oJsTgNUCJwSzVqxcmZ4DuPHGtEyb1nK51VZLDcDjx8N++6U2\nAI/bb7XICcEsZ9kyuOMOuP56uOGG1mf2GjwYPvGJtOy7L/Tv37VxmlWCE4L1eEuXpqqga6+Fv/89\nzfdbTErdPz/5yZQERo1yNZDVHycE65FWrEh3ApMnw9/+1vKwEGuumaqBPv3plAQ22qjr4zTrSk4I\n1mNEpCeEr7wyJYKWqoP6908J4KCD4GMf81AQ1rM4IVjde+21lAT++MeWG4b79UsJ4NBDU68gDwFt\nPZUTgtWlpUtTw/Dvfw+33w6Njc2P9+2b2gM+9znYf39YY42qhGnWrTghWF15+mn47W/hiitaflp4\n7Fj4whfgkENgwICuj8+sO3NCsJq3ciXcdBOcdx784x/vPz50KBx1FBx5JGy5ZZeHZ1YznBCsZi1e\nnKqEzj0Xnn+++bE11oDPfhaOPhr22stjBZm1R0UTgqQ9gccioh1TfJu1z7x58KtfwYUXwttvNz+2\nzTZwwgmpWmjgwOrEZ1arKn2HcAuwE/Bihb/HeoA5c+DnP4df/xreeaf5sX33hYkT4eMf992AWakq\nnRD8LKd12ttvw9lnp7uC/IByvXvD4YfDd7+bnhw2s86p+m8pSSdLekTSQklzJf1N0jYtlPuRpNmS\nFku6XdKwouN9JV0oaZ6kRZKulbRRUZmBkq6StEDSfEmXSlq7qMxmkm6S9I6kOZLOltSrqMxISfdI\nWiLpZUnfayHefSQ1SFoq6VlJR3XuL9XzvPMO/PjHsMUWcNZZTcmgb99ULfT886k3kZOBWXlUPSEA\nY4Hzgd2BfYE+wG2S3pszStJJwNeBY4DdgHeAKZLyjxCdBxwAHAzsBWwCXFf0XVcDI4BxWdm9gEty\n39MLuJl057QHcBTwReBHuTLrAlOAmcBo4HvAJElfyZUZCvwduBMYBfwSuFTSxzr0l+mhli9P1ULD\nhsEppzSNLbT66vCtb6VhqC+4AD7wgerGaVZ3IqJiC7AI2LKD79kAaAQ+nNs3G5iY2+4HLAEOzW0v\nAz6TKzM8+5zdsu0R2fbOuTLjgRXA4Gx7f2A5sEGuzLHAfKB3tn08MK+wne37KTAtt30W8GTReU0G\nbm7jvEcD0dDQED1VY2PEX/8asc02EWmgibT06hVx9NERL79c7QjNalNDQ0MAAYyONq6/lb5DiBLe\nMyB739sAkrYABpN+bacPjVgIPAx8MNu1C+lXfb7MDOCVXJk9gPkR8Xjuu+7Ivmv3XJmnImJerswU\noD+wfa7MPRGxoqjMcEn9c2XuKDqvKblYrMijj6aHxg46CJ59tmn/QQfBM8/ApZfC5ptXLz6znqDS\nCaFDjcqSRKr6uS8iCqPODCZdtOcWFZ+bHQMYBLybJYrWygwGmg1nFhErSYknX6al76FMZfpJ6ou9\nZ+7c9KzAbrvB/fc37R87Nk1Oc911ac5hM6u8knsZSeoN7ANsBVwdEYskbQIsjIj/AkTEuh382IuA\n7YA9S42rityjqgNWroRLLoGTT24+/8C226YeRZ/8pOcbMOtqJSUESR8AbgU2B/oCt5PaC07Kto8r\n4TMvAD4BjI2I13OH5pAutoNo/qt7EPB4rszqkvoV3SUMyo4VyhT3OloNWK+ozK5FoQ3KHSu8Dmqh\nTLSjzMJYxUN6EydOpH/R9FsTJkxgwoQJbb2tpjzxBBx7LDz8cNO+/v3h9NPha1+DPn2qF5tZrZs8\neTKTJ09utm/BggXte3NbDQytLcD1wBXA6uQajkl3DM+V8HkXAK/SSgM0rTcqH5LbXlWj8rbASpo3\nKu9H80blj/P+RuVjSI3KfbLt40iNyqvlyvyE5o3KZwJPFJ3D1fTwRuVlyyJOPTWid+/mjcZf+lLE\n3LnVjs6sfrW3UbnUhPAWMDyKehIBQ4HFHfysi7IL7ljSr+jCskauzInZdx4I7JglpOeA1Ys+Z2aW\nlMYA9wP3Fn3XzcBjpLuAPYEZwBW5472AJ0hPWI8k9UKaC5yRK9MvS1B/IFVvHQb8Fzg6V2Zo9nc5\nK0tMXwPeBfZt4+9Q1wnhX/+KGDWqeSIYMSLi7rurHZlZ/at0QpgPbBfvTwgfBuZ28LMas1/uxcuR\nReUmZRfixaQeO8OKjvclPc8wL4vpL8BGRWUGAFcCC7Jz+C2wVlGZzUjPEPw3SwZnAb2KyuwA3J3F\n8grw3RbOay+ggXQn8xzwhVX8HeoyIaxcGfGzn0X06dOUCHr3TncKS5dWOzqznqG9CUERHe8ZKuka\nYEFEHCNpEenX9JvA/wNeiYgvdfhDezhJo4GGhoYGRo8eXe1wymLWrDTkdH5I6h13hD/8AXbeuXpx\nmfU0U6dOZcyYMQBjImJqa+VK7Xb6HWBPSdOANUj14y8Bm5Ialq2H+9vfYOTIpmQgwYknwmOPORmY\ndVcl9TKKiFmSRpHqz0cB6wCXAVdFxJI232x1bckS+M534OKLm/YNGZLmM/7IR6oXl5mtWsnPIUR6\nUveqbDFj1iz4n/+BhoamfQcfDL/5Day3XvXiMrP2KanKKBuh9H3tBJK+nA1EZz3MQw/Brrs2JYM1\n10yJ4C9/cTIwqxWltiEcC0xrYf8zlPBQmtW2K6+EvfdOE9hAGq764Yfhq1/108ZmtaTUhPC+cYEy\nbwIblx6O1ZLGRvj+99N0le++m/btsw888kjqTWRmtaXUhPAqLY83tCfpWQGrc4sXwyGHwE9/2rTv\n2GPhtttggw2qF5eZla7URuXfAudJ6gPcle0bB5wN/KIcgVn3NX8+HHhg0+ikvXrBeefB17/uKiKz\nWlZqQvgZsD5puIjCrGVLgbMi4qetvstq3uzZaSL7p55K2+uuC3/+c9pnZrWt1OcQAjhJ0hmkmciW\nkAa1a3MkT6ttr7yS2ghmzkzbG24It94KdfJgtVmPV/JzCACR5j14tEyxWDf26qvNk8HQoam9YOut\nqxmVmZVTqfMhrA38L6ndYCOKGqcjYsvOh2bdxaxZ6SnjQjLYZhu46y7YdNPqxmVm5VXqHcKlwN6k\nORFep7S5k60GzJ0L48bBCy+k7WHDnAzM6lWpCWF/4ICIuH+VJa1mzZ8P48c3TXq/1VZpsDonA7P6\nVOpzCPNJk9NbnXrnHTjggDTdJcBmm6U7gyFDqhuXmVVOqQnhh8CPJK1VzmCse1i+PA1K9+CDaXvD\nDeGOO2Dzzasbl5lVVqlVRt8BtgLmSnqJNA/xeyLCHRFrVEQag2jKlLTdv3/qTbTNNtWNy8wqr9SE\ncH1Zo7Bu49RT04xmAH37wo03wk47VTcmM+sapT6Ydnq5A7Hqu+wy+L//S+sSXHUVjB1b3ZjMrOuU\n2oZgdeahh+D445u2zzsvtSOYWc9R6oNpqwETgUOBzWkazwiAiPCUKDVkzpx08V+etQR94xvwzW9W\nNyYz63ql3iGcBnwbuAboD5wD/BVoBCaVJTLrEsuXw6GHpkHrAPbaC37h8WrNeqRSE8LngK9GxC+A\nFcDkiPgK8CNgj3IFZ5U3aRLce29a33TTNHJpnz5VDcnMqqQzM6ZlAyDzX9JdAsDfgQM6G5R1jUcf\nhTPPTOt9+sC118KgQdWNycyqp9SEMIumqTJfAPbL1ncFPAR2DVi6FI46Kk2DCam76R6+tzPr0UpN\nCH8jjXQKcD5whqTngD8Cl5cjMKus006D6dPT+pgxcNJJ1Y3HzKqv1OcQ/je3fo2kV4APkibJubFc\nwVllPPoo/PznaX311eH3v3e7gZl1coKcgoh4EHiwHJ9lldXYCCec0FRVNGkS7LBDVUMys26i3QlB\n0qeAWyJiebbeqoi4odORWUVcdlm6QwDYfnv47nerG4+ZdR8duUO4ntS76A3aHssogNU6E5RVxltv\nwcknN21fcIGrisysSbsTQkT0amndascPfpCSAsCECWmOZDOzgg5f2CX1kXSnJE+vXkOefBJ+85u0\nvs46TY3KZmYFHU4IEbEcGFmBWKyCvv/9NNcBwA9/CJtsUt14zKz7KbXq50rg6HIGYpVz771w001p\nfcgQD1xnZi0rtdtpb+DLkvYFGoB38gcj4tudDczKI6L5Q2ennw5rrFG9eMys+yo1IewATM3WiydX\njNLDsXK78camuZFHjIAjj6xuPGbWfZX6pPJHyh2IlV9jY2o7KPjJT6B3WR5FNLN65O6jdey66+CZ\nZ9L6HnvApz9d3XjMrHsr+feipF1ofca0gzoZl3VSY2PT/MiQ2g6k6sVjZt1fSXcIkg4HHgBGAJ8B\n+gDbAx8FFpQtOivZDTekZw8AdtsNPvax6sZjZt1fqVVG3wcmRsSBwLvAt4BtgT8Dr5QpNitRBJxx\nRtP2qaf67sDMVq3UhLAVkPVs511g7YgI4FzgmHIEZqW75RaYmvUBGz0aPvGJ6sZjZrWh1IQwH1g3\nW3+N1A0VYACwVmeDstJFNG87OOUU3x2YWfuU2qh8D/Ax0rzKfwF+Kemj2b47yxSbleDee5ueO9hh\nB/csMrP2K/UO4evAn7L1HwPnAIOA6yhhSAtJYyXdIOk1SY3F8y1I+l22P7/cXFSmr6QLJc2TtEjS\ntZI2KiozUNJVkhZImi/pUklrF5XZTNJNkt6RNEfS2ZJ6FZUZKekeSUskvSzpey2c0z6SGiQtlfSs\npKM6+ncpxdlnN62fdBL0csdiM2unUh9Mezu33gic2ck41gb+BVwG/LWVMrcAXwQKFSDLio6fB+wP\nHAwsBC4kJaixuTJXkxLXOFJX2d8DlwCfB8gu/DcDs4E9gE2AK0jtJKdkZdYFpgC3AccCOwK/kzQ/\nIi7NygwF/g5cBBwB7AtcKml2RNzevj9Jxz39dNOYRZtvDocdVqlvMrN6VFJCkHQHaYC7v0bEws4G\nERG3Ardmn91ajfeyiHizlXj6AV8GDo+Iu7N9XwKmS9otIh6RNAIYD4yJiMezMt8AbpL03YiYkx3f\nFvhIRMwDnpL0Q+BMSZMiYgUpefQBjs62p0vaGfg2cGkW0vHAixFxYrY9Q9KHgYlAxRJC/u7g29/2\n5Ddm1jGlVig8A/wUmCPpL5I+LanSl599JM2V9G9JF0laL3dsDCm5vdd+EREzSF1gP5jt2gOYX0gG\nmTtIYy/tnivzVJYMCqYA/UnPWRTK3JMlg3yZ4ZL658rcURT/lFwsZffKKzB5clpfbz34ylcq9U1m\nVq9KSggR8S1gU+B/SCOd/hGYK+k3kvYuY3wFtwBHkh58OxHYG7g5dzcxGHi3hbuVudmxQpk3is5j\nJfB2UZm5LXwGZSrTT1LfFs6v0375S1iRpaivfx3WXrvt8mZmxUoeuiJrO7gNuE3SccCBwA9Ijcpl\nnVM5Iv6c23xG0lPAC8A+wD/K+V2dUJbOnRMnTqR///7N9k2YMIEJEya0+p7Fi+Hyy9N6374pIZhZ\nzzR58mQmF6oLMgsWtG8AiU6PfSlpMHA4qW59JPBIZz9zVSJipqR5wDBSQpgDrC6pX9FdwqDsGNlr\nca+j1YD1isrsWvR1g3LHCq+DWigT7SizMCKKG8ObOffccxk9enRbRd7nmmvgP/9J64cdBhtu2KG3\nm1kdaekH5NSpUxkzZswq31vqWEb9JH1J0u3Aq6RG1BuArSNij1I+s4PfPwRYH3g929UArCD1HiqU\nGU4aeC/rlc+DwICsAbhgHOmX/cO5MjtK2iBXZj/S+EzTcmX2ypJJvsyMiFiQKzOO5vbLxVJWF1/c\ntH788ZX4BjPrCUq9Q5hLelr5GuDkiHisM0FkzwIMo6naZUtJo0j1+28Dp5G6kM7Jyp0FPEtqqCUi\nFkq6DDhH0nxgEfAr4P6IeCQr829JU4DfSjqe1O30fGBy1sMIUhXYNOAKSScBGwNnABdkc0lD6rp6\nKnC5pLNI3U6/SRrPqeDXwAnZ8ctJyeGzQNkHkWhogEcfTes77QS77952eTOz1pSaED4F3Jm1I7RK\n0p7AY6uqJgF2IVX9RLb8Itv/B+BrpKqoI0lDY8wmJYJTcxdpSF06VwLXAn1J3VhPKPqeI4ALSD2A\nGrOy713II6JR0ieBi0mjub5DelbhtFyZhZL2Iz3n8BgwD5gUEZflyrwk6QDS2E7fBGaRuqkW9zzq\ntOK7Aw9TYWalUhqTrkIfLi0EdoqIFyv2JXVC0migoaGhod1tCP/5D2y6aWpUXnddmD0b1lmnsnGa\nWe3JtSGMiYiprZWr9MAG/r1aQVdfnZIBwBe+4GRgZp3jkW5q2DXXNK0f40HHzayTnBBq1OzZaWRT\ngG23hZEjqxuPmdU+J4Qadd11ae4DgEMPdWOymXVepRNC5Vqse7g/557dPvTQ6sVhZvXDjco16LXX\n4L770vp228H227dd3sysPTo9dEVbImLdVZeyjrr22qZ13x2YWbm0OyFIepx2VgFFRMcG47EOyVcX\nHXJI9eIws/rSkTuE63Pra5CeIJ5G0/g8e5DmDLioPKFZS2bNggceSOvbb5+qjMzMyqHdCSEiTi+s\nS7oU+FVE/DBfRtLpwGblC8+K3XVX0/pnP1u9OMys/pTaqHwIaVKcYleS5jS2Cnk8N9/bhz5UvTjM\nrP6UmhCWAHu2sH9PYGnp4diqTM2NQrLzzq2XMzPrqFJ7GZ0HXJwNyFaYEGd30kT3Z5QjMHu/xkb4\n17/S+pAhngjHzMqrpIQQEWdKepE0dPTns93TgS8VTXdpZTRzJizM5oPz3YGZlVtn5lT+M+CLfxfK\ntx84IZhZuZX8pLKkAZK+IuknktbL9o2WtGn5wrM8JwQzq6SS7hAkjSTNOrYAGApcSprq8iDSPMZH\nlik+y3FCMLNKKvUO4Rzg9xGxNc17Fd0M7NXpqKxFhYQwcCBsvnl1YzGz+lNqQtgVuKSF/a8Bg0sP\nx1rz+uswZ05aHz3aw12bWfmVmhCWAf1a2L8N8Gbp4VhrXF1kZpVWakK4AThVUp9sOyRtDpwFXFeW\nyKwZJwQzq7RSE8J3gHWAN4A1gbuB54FFwA/KE5rlOSGYWaWV+mDaAuBjkj4MjCQlh6kRcUc5g7Mm\nhYSw1lqwzTbVjcXM6lOnJsiJiPuA+8oUi7ViwQJ48cW0PnIkrLZadeMxs/pUckKQNA4YB2xEUdVT\nRHy5k3FZzjPPNK3vtFP14jCz+lbqg2mnAacCjwGv086Z1Kw0+YTg+ZPNrFJKvUM4DvhiRFxRzmCs\nZdOmNa17hjQzq5RSexmtDjxQzkCsdU4IZtYVSk0IlwJHlDMQa10hIQwcCIMGVTcWM6tfpVYZrQEc\nI2lf4Elgef5gRHy7s4FZsmABzJqV1rff3kNWmFnllJoQRgLZ3F3sUHTMDcxlNH1607qri8yskkp9\nMO0j5Q7EWub2AzPrKiVPkGNdwwnBzLpKu+8QJP2V1NV0Ybbeqog4qNORGdA8IfgZBDOrpI5UGS2g\nqX1gQQVisRYUHkrr3x823ri6sZhZfWt3QoiIL7W0bpWzaBG88kpa32479zAys8pyG0I39u9/N627\n/cDMKq0zg9t9FjgU2Jz05PJ7ImJ0J+My3KBsZl2rpDsESd8EfgfMBXYGHgHeArYEbilbdD2cB7Uz\ns65UapXR14BjIuIbwLvA2RHxMeBXQP9yBdfT+Q7BzLpSqQlhc5oGt1sCrJutXwFM6GxQlhQSwjrr\nwJAh1Y3FzOpfqQlhDrBetv4KsEe2vgXgvjBlsHQpvPRSWh8xwj2MzKzySk0IdwGfytZ/B5wr6Xbg\nGuBv5Qisp3vxRYjsqY+tt65uLGbWM5Tay+gYsmQSERdKegv4EHADcEmZYuvRnnuuad0Jwcy6Qkl3\nCBHRGBErctt/iohvRsT5EfFuRz9P0lhJN0h6TVKjpE+1UOZHkmZLWizpdknDio73lXShpHmSFkm6\nVtJGRWUGSrpK0gJJ8yVdKmntojKbSbpJ0juS5kg6W1KvojIjJd0jaYmklyV9r4V495HUIGmppGcl\nHdWRv8nzzzetDxvWejkzs3LpyFhGI9tbNiKe7GAca5OG074MeN84SZJOAr4OHAm8BPwfMEXSiFwC\nOg/YHzgYWAhcCFwHjM191NXAIGAc6dmJ35PuaD6ffU8v4GZgNqldZBNSQ/m7wClZmXWBKcBtwLHA\njsDvJM2PiEuzMkOBvwMXkSYS2he4VNLsiLi9PX8Q3yGYWZeLiHYtQCOwMntta1nZ3s9s43s+VbRv\nNjAxt92P1Lvp0Nz2MuAzuTLDs8/aLdsekW3vnCszHlgBDM629ydN9rNBrsyxwHygd7Z9PDCvsJ3t\n+ykwLbd9FvBk0TlMBm5u47xHA9HQ0BAREePGRaRWhIh588LMrGQNDQ1BGotudLRx/e1IldEWpAfP\ntljFsmUHPnOVJG0BDAbuLOyLiIXAw8AHs127kO528mVmkHpAFcrsAcyPiMdzH38H6Y+0e67MUxEx\nL1dmCunZiu1zZe6JXJVZVma4pP65MncUncqUXCyrVLhDGDgQ1l+/ve8yMytdRwa3e7mSgbRhMOmi\nPbdo/9zsGKRqoHezRNFamcHAG/mDEbFS0ttFZVr6nsKxJ7LXF9sos6CNz+knqW9ELKMNS5fCq6+m\ndbcfmFlX6cxYRsOBb5CqYgCmA+dnv8x7orI8KTBx4kR69er/XpfT2bNh8uQJTJjg5/3MbNUmT57M\n5MmTm+1bsKB9MxaUlBAkHQz8CXgMeDDbvQfwtKTDI+K6Uj63FXNIF9tBNP/VPQh4PFdmdUn9iu4S\nBmXHCmWKex2tRnrALl9m16LvH5Q7Vngd1EKZaEeZhau6Ozj33HOZNWs0//xn2j76aHAuMLP2mjDh\n/T8gp06dypgxY1b53lIfTDsb+GlEfDAivp0tHwJ+kh0rm4iYSbrAjivsk9SPVO9fGD6jgdQ4nC8z\nnDTERiFhPQgMkLRz7uPHkZLNw7kyO0raIFdmP1I10LRcmb2yZJIvMyMiFuTKjKO5/XKxtMk9jMys\nGkpNCBsDf2xh/5XZsQ6RtLakUZJ2ynZtmW1vlm2fB5wi6UBJO2bfPQv4f/BeI/NlwDlZ//8xwOXA\n/RHxSFbm36SG3d9K2lXSnsD5wOSIKPyyv4104b8ie9ZgPHAGcEFELM/KXE3qhnq5pO0kHQZ8E/hF\n7pR+nZ3DWZKGS/oa8FngnPb8PfwMgplVQ6ltCP8k9e9/vmj/h4F7S/i8XYB/kKpdgqaL6x+AL0fE\n2ZLWIj2HTu66AAAPSklEQVQzMCD7jv2j+UNwE0ndYq8F+gK3AicUfc8RwAWkHkCNWdlvFQ5GRKOk\nTwIXk+4+3iE9q3BarsxCSfuRnnN4jNQFdVJEXJYr85KkA4BzScliFnB0RBT3PGqR7xDMrBoUhdbL\njrxJOg74EfBn4KFs9x7AIaSL5+xC2Yi4ofNh1j9Jo4GGhoYGDjpoNC+/DAMGwNtve2A7M+ucXBvC\nmIiY2lq5Uu8QLspev5YtLR2D9Gt/Nazdli1rmkd5662dDMys65SUECLCczFXyOzZTaOcuv3AzLpS\n2S/sWV2/lahwdwBuPzCzrlXqnMp3Stq0hf27kwapsxIVnlAG3yGYWdcq9Q5hKfBk1uUSSb0kTSL1\n/rm5TLH1SL5DMLNqKbUN4QBJJ5D64n8aGAp8APhkRNxWxvh6HN8hmFm1lDyWUaSZ0oYAJ5GeEt4n\nIh5YxdtsFeZl46yuuaZHOTWzrlVqG8JASdeR5gY4lvQ8wm3ZE7nWCYsWpdeBA93l1My6Vql3CE8D\nM0mTzcwkDQdxGHCRpAMi4oCyRdjD5BOCmVlXKrVR+dfAXlkyACAirgFGkaamtBItXZpeBwyobhxm\n1vOUlBAi4gxgT0lXSnow1wX1I6QhLayTnBDMrKuV2oZwMGnk0CXAzqTB5CBNNXlyeULr2VxlZGZd\nrdQqo1OA4yLiq6RJ6QvuJ00Wb53kOwQz62qlJoThwD0t7F9AGp7aOskJwcy6WqkJYQ7Q0mNTH+b9\nE9BbCZwQzKyrlZoQfgv8Mhu7KIBNJH0O+DlpchnrJLchmFlXK/U5hDNJyeROYC1S9dEy4OcRcX6Z\nYuvRfIdgZl2t1LGMAvixpJ+Rqo7WAaZFxH/LGVxP5oRgZl2t5LGMALI5jaeVKRbLcZWRmXU1z3zW\nTfkOwcy6mhNCN+WEYGZdzQmhG5Kgf/9qR2FmPY0TQjfUrx/08r+MmXUxX3a6IVcXmVk1OCF0Q04I\nZlYNTgjdkLucmlk1OCF0Q75DMLNqcELohpwQzKwanBC6IVcZmVk1OCF0Q75DMLNqcELohpwQzKwa\nnBC6IVcZmVk1OCF0Q75DMLNqcELohpwQzKwanBC6IScEM6sGJ4RuyG0IZlYNTgjdkO8QzKwanBC6\nmV69YO21qx2FmfVETgjdTL9+aYIcM7Ou5oTQzayzTrUjMLOeygmhm1l33WpHYGY9lRNCN9OvX7Uj\nMLOeygmhm/EdgplVixNCN+OEYGbVUhMJQdJpkhqLlmlFZX4kabakxZJulzSs6HhfSRdKmidpkaRr\nJW1UVGagpKskLZA0X9KlktYuKrOZpJskvSNpjqSzJfUqKjNS0j2Slkh6WdL32nuuTghmVi01kRAy\nTwODgMHZ8uHCAUknAV8HjgF2A94BpkhaPff+84ADgIOBvYBNgOuKvuNqYAQwLiu7F3BJ7nt6ATcD\nvYE9gKOALwI/ypVZF5gCzARGA98DJkn6SntOsp4TwuTJk6sdQsXV+znW+/lBzzjH1tRSQlgREW9G\nxBvZ8nbu2LeAMyLi7xHxNHAk6YL/PwCS+gFfBiZGxN0R8TjwJWBPSbtlZUYA44GjI+KxiHgA+AZw\nuKTB2feMB7YFPhcRT0XEFOCHwAmSemdlPg/0yT5nekT8GfgV8O32nKQTQm2r93Os9/ODnnGOraml\nhLC1pNckvSDpSkmbAUjagnTHcGehYEQsBB4GPpjt2oX0qz5fZgbwSq7MHsD8LFkU3AEEsHuuzFMR\nMS9XZgrQH9g+V+aeiFhRVGa4pP6rOsl6Tghm1r3VSkJ4iFQ1Mx44DtgCuCer3x9MumjPLXrP3OwY\npKqmd7NE0VqZwcAb+YMRsRJ4u6hMS99DB8u0yt1Ozaxaeq+6SPVlVTMFT0t6BHgZOBT4d3WiqozL\nLpvIbbc1v5GYMGECEyZMqFJEZlZLJk+e/L5qrwULFrTrvTWREIpFxAJJzwLDgH8CIt0F5H+ZDwIK\n1T9zgNUl9Su6SxiUHSuUKe51tBqwXlGZXYvCGZQ7VngdtIoyLVkD4IgjjmHcuBHvOzh16tQ23lob\nFixYUBfn0ZZ6P8d6Pz+o/XMcPnw4kyZNarZv+vTp3HPPPZBdZ1oVETW3AOuQqnJOyLZnkxqMC8f7\nAUuAQ3Lby4DP5MoMBxqB3bLtbYGVwM65MvsBK4DB2fbHgeXABrkyxwDzgT7Z9nHAPGC1XJmfANNW\ncU5HkKq+vHjx4qVSyxFtXYeUXYy6NUk/A24kVRNtCpwOjAS2i4i3JJ0InERqZ3gJOIPUyLt9RLyb\nfcZFwP6k3kWLSD1/GiNibO57bibdJRwPrA5cDjwSEV/Ijvci3XXMzr5vY+CPwG8i4odZmX6kaqzb\ngbOAHYHLgG9FxGVtnOP6pDaSl4Clpf6tzMxasAYwFJgSEW+1VqhWEsJkYCywPvAmcB/wg4iYmSsz\nifRrfQBwL+nu4fnc8b7Az4EJQF/g1qzMG7kyA4ALgANJdw/Xki7ki3NlNgMuBvYhPe/we+DkiGjM\nldkBuJBUvTQP+FVE/LwsfwwzswqpiYRgZmaVVyvdTs3MrMKcEMzMDHBCMDOzjBNCNyDpBEkzs9FR\nH5JU/KxDTZB0sqRHJC2UNFfS3yRt00K5NkemrSWS/jcbffecov01fY6SNpF0RTY68GJJT0gaXVSm\nJs9RUi9JZ0h6MYv9eUmntFCuJs+vM5wQqkzSYcAvgNOAnYEnSCO1blDVwEozFjifNPbTvqRB/m6T\ntGahQDtHpq0JWeI+hvRvlt9f0+eY9ba7n/TsznjSCMDfIT1vUyhTy+f4v8CxwNdIzx+dCJwo6euF\nAjV+fqWr9kNmPX0hjdP0y9y2gFnAidWOrQzntgGp++6Hc/tae4jw0GrH28FzWweYAXwU+AdwTr2c\nI3AmcPcqytTsOZKeafpt0b5rgT/Ww/l1ZvEdQhVJ6gOMofkorEEaZfWDrb2vhgwgPR35NrR7ZNpa\ncSFwY0Tcld9ZJ+d4IPCYpD9nVX9T8/N51ME5PgCMk7Q1gKRRwJ6kuU7q4fxKVpNjGdWRDYDVaHl0\n1OFdH075SBJpUqL7IqIwu117Rqbt9iQdDuxEGla9WD2c45akp/V/AfyYVGXyK0nLIuIKav8czyT9\n4v+3pJWkqvMfRMSfsuO1fn4lc0KwSrkI2I70y6tuSBpCSnT7RsTyasdTIb1IQ7b8MNt+Inv6/jjg\niuqFVTaHkcYOOxyYRkruv5Q0O0t4PZarjKprHmlAvZZGR21rZNRuTdIFwCeAfSLi9dyhOTSNTJtX\nS+c7BtgQmCppuaTlwN7AtyS9S/oVWevn+DowvWjfdGDzbL3W/x3PBs6MiL9ExDMRcRVwLnBydrzW\nz69kTghVlP3CbCDN4Qy8V9UyjlTPWXOyZPBp4CMR8Ur+WKSxp+bQ/Hz7kXol1cr53kEasHAnYFS2\nPAZcCYyKiBep/XO8n/dXWQ4nDS5ZD/+Oa5F+iOU1kl0P6+D8SlftVu2evpAm+VlMmgd6W+AS4C1g\nw2rHVsK5XETqmjiW9GuqsKyRK3Nidn4Hki6s1wPPAatXO/5OnHdxL6OaPkdS28gy0i/mrUjVK4uA\nw+vhHIHfkabP/QTwAeAzpNkSf1IP59epv021A/ASkPpDv0Tq1vYgsEu1YyrxPBpJv7yKlyOLyk0i\ndetbTJpveli1Y+/ked+VTwj1cI7ZxfLJLP5ngC+3UKYmzxFYGzgHmEl6vuA50pD6vevh/DqzeLRT\nMzMD3IZgZmYZJwQzMwOcEMzMLOOEYGZmgBOCmZllnBDMzAxwQjAzs4wTgpmZAU4IZmaWcUIwMzPA\nCcHMykxSo6RPVTsO6zgnBDMzA5wQrAeS9A9Jv5R0lqS3JL0u6bR2vre/pEskzZG0RNKTkj6RO36w\npKclLZU0U9K3i94/U9IPJP1B0iJJL0k6UNIGkq7P9j0haUzuPUdJmi/p05Kezb731mz2tvxnHy/p\neUnLJE2X9Pmi442Sjpb0V0nvZJ91YFGZHSTdnMUxR9IfJa3f3r+dpJmk6Sevz77vxWz/KEl3SVoo\naYGkRyWNbs/f3LpQtYdb9eKlqxfS/AXzgR+Sxvv/AmmY7nGreJ9Iw5M/CXwUGAqMB8Znx8cAK4Dv\nA8NIc1y8Q274b9KQy28CX8m++wLgP8BNwMHZ+/4KPJ17z1Gk+QkeJs1vvDPwEHBvrsxnsjLHZp8x\nEVgO7J0r00ia5OZQ0rzJ5wELgQHZ8f6kGd/OALYmTf5zK3Bne/92pHnCG7P9GwHrZ/ufAv6Qfe5W\n2bnuWO3/FrwU/Tde7QC8eOnqJbuo3V2072FyE6S08r79sovsVq0cvxK4tWjfWcBTue2ZwO9z24Oy\nC+hpuX27ZxfZjbLto7LtXXJlhmfv2yXbvg+4uOi7rwFuzG03ApNy22tl+/bLtn8A3FL0GUOyMsPa\n+7fLyn+qqMwC4AvV/rf30vbiKiPrqZ4s2n6d9Iu2LaOAWRHxQivHR5Cmn8y7H9g6mxq14KnCSkTM\nzVafzh0vzMucj2dFRDyWe98M0p3FiNx3F0/veH/ueEvfvZh0h1D4nlHAR7PqokWSFpHmUg7Sr/qC\nUv525wCXSbpd0kmStlxFeasCJwTrqZYXbQer/v9hSYW+u3hfYdaqSvz/2dZ5rwPcAIykab7oUaRq\nnnva+RktiojTge2Av5Oq256R9OkS4rcKckIwa78ngSGShrVyfDqwZ9G+DwPPRlZv0gm9Je1S2JA0\nHBgATGvju/fMHW+PqcD2wMsR8WLR0pFkuBxYrXhnRDwfEb+MiPHA34AvdeAzrQs4IZi1U0TcA9wL\nXCdpX0lDJX1c0visyC+AcZJOkbS1pKOAE4CfleHrVwDnS9ot64H0O+CBiGjIjv8M+KKk4yQNy3o3\nfaaD330hsB7wJ0m7SNpS0nhJlxdVea3KS6S/wyBJAyStIel8SXtL2lzSnsCudCxZWRdwQrCeqDO/\n1g8CHgWuJk0+fxbZ/0cR8TipB89hpLr6ScApEXHFKr67Pfveyb7ralJSWggc/l7hiP8HfAv4Dqk9\n4qvAFyPi3vZ+T0S8Trqr6EWaVP5JUt3//NwdTnv+dt8BPga8SrrrWAGsT+plNAP4E6lX1aR2fJZ1\nIXX+TtbMKim70zg3ItardixW33yHYGZmgBOC2XskHZHvclm0PLXqTzCrba4yMstIWpv0oFhLlkfE\nq10Zj1lXc0IwMzPAVUZmZpZxQjAzM8AJwczMMk4IZmYGOCGYmVnGCcHMzAAnBDMzy/x/L1BS0iU8\nGUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8e2aaeb750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 100\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(np.cumsum(pca.explained_variance_), linewidth=2)\n",
    "    \n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Decision Tree\n",
    "#\n",
    "# param_grid para a GridSearchCV:\n",
    "#param_grid = {'max_depth': [10, 25, 50, 75, 100, 150, 200, 400],\n",
    "#              'criterion': ['gini', 'entropy'],\n",
    "#              'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "#              'class_weight': ['balanced', None]\n",
    "#              }\n",
    "#clf = GridSearchCV(DecisionTreeClassifier(), param_grid)\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "#print(clf.best_estimator_)\n",
    "\n",
    "#melhor escolha\n",
    "clf = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=400,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\n",
    "clfss.append(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Naive Bayes\n",
    "#\n",
    "#pega a proporção de cada classe pra usar como prior no naive Bayes\n",
    "proportion = []\n",
    "parent_path = 'lfw_funneled'\n",
    "\n",
    "for name in target_names:\n",
    "    proportion.append(float(len(os.listdir(('lfw_funneled/'+ name).replace(' ', '_')))) / float(n_samples) )\n",
    "    \n",
    "#print('Proporções de cada classe ', proportion)\n",
    "\n",
    "#executa o naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#clf = GaussianNB(priors = proportion)\n",
    "clf = GaussianNB()\n",
    "\n",
    "clfss.append(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNeighborsClassifier\n",
    "#\n",
    "#param_grid para a GridSearchCV:\n",
    "#param_grid = {'n_neighbors': [2, 4, 5, 6, 8, 20, 50, 100, 200, 400],\n",
    "#              'algorithm': ['brute', 'ball_tree', 'kd_tree'],\n",
    "#              'weights': ['uniform', 'distance']}\n",
    "#clf = GridSearchCV(KNeighborsClassifier(), param_grid)\n",
    "\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "#print(clf.best_estimator_)\n",
    "\n",
    "#resultado da melhor escolha\n",
    "clf = KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=4, p=2,\n",
    "           weights='distance')\n",
    "\n",
    "clfss.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# LDA\n",
    "#\n",
    "#\n",
    "#param_grid = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "#\n",
    "#clf = GridSearchCV(LDA(), param_grid)\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "#print(clf.best_estimator_)\n",
    "\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "#y_pred = clf.predict(X_test_pca)\n",
    "#analyzeFeaturesLDA(X_test_pca, y_test, clf)\n",
    "\n",
    "\n",
    "#resultado da melhor escolha\n",
    "clf = LDA(n_components=None, priors=None, shrinkage=None,solver='svd', store_covariance=False, tol=0.0001)\n",
    "clfss.append(clf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train a SVM classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "#\n",
    "#print(\"Fitting the classifier to the training set\")\n",
    "#t0 = time()\n",
    "#param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "#              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "#clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "#print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print(\"Best estimator found by grid search:\")\n",
    "#print(clf.best_estimator_)\n",
    "\n",
    "#resultado selecionado\n",
    "#SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "#  decision_function_shape=None, degree=3, gamma=0.005, kernel='rbf',\n",
    "#  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#  tol=0.001, verbose=False)\n",
    "\n",
    "clf = SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "  decision_function_shape=None, degree=3, gamma=0.005, kernel='rbf',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "\n",
    "clfss.append(clf)\n",
    "\n",
    "\n",
    "#clf = clf.fit(X_train_pca, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Quantitative evaluation of the model quality on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "================================================\n",
      "medindo componentes\n",
      "================================================\n",
      "================================================\n",
      "treinando classificadores\n",
      "================================================\n",
      "================================================\n",
      "Predição classificador DecisionTreeClassifier\n",
      "================================================\n",
      "done in 0.000s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.25      0.38      0.30        13\n",
      "     Colin Powell       0.50      0.37      0.42        60\n",
      "  Donald Rumsfeld       0.26      0.33      0.30        27\n",
      "    George W Bush       0.73      0.64      0.68       146\n",
      "Gerhard Schroeder       0.22      0.24      0.23        25\n",
      "      Hugo Chavez       0.23      0.40      0.29        15\n",
      "       Tony Blair       0.31      0.36      0.33        36\n",
      "\n",
      "      avg / total       0.52      0.48      0.49       322\n",
      "\n",
      "[[ 5  5  1  2  0  0  0]\n",
      " [ 6 22  2 14  5  0 11]\n",
      " [ 4  1  9  7  3  1  2]\n",
      " [ 4 10 13 94  5 12  8]\n",
      " [ 1  2  5  3  6  3  5]\n",
      " [ 0  1  0  3  2  6  3]\n",
      " [ 0  3  4  6  6  4 13]]\n",
      "================================================\n",
      "Predição classificador GaussianNB\n",
      "================================================\n",
      "done in 0.002s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.54      1.00      0.70        13\n",
      "     Colin Powell       0.84      0.70      0.76        60\n",
      "  Donald Rumsfeld       0.70      0.52      0.60        27\n",
      "    George W Bush       0.79      0.90      0.84       146\n",
      "Gerhard Schroeder       0.71      0.68      0.69        25\n",
      "      Hugo Chavez       0.89      0.53      0.67        15\n",
      "       Tony Blair       0.78      0.58      0.67        36\n",
      "\n",
      "      avg / total       0.78      0.77      0.76       322\n",
      "\n",
      "[[ 13   0   0   0   0   0   0]\n",
      " [  3  42   3   9   0   1   2]\n",
      " [  2   3  14   7   1   0   0]\n",
      " [  5   4   1 132   2   0   2]\n",
      " [  0   0   1   5  17   0   2]\n",
      " [  1   0   0   3   3   8   0]\n",
      " [  0   1   1  12   1   0  21]]\n",
      "================================================\n",
      "Predição classificador KNeighborsClassifier\n",
      "================================================\n",
      "done in 0.009s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       1.00      0.69      0.82        13\n",
      "     Colin Powell       0.62      0.67      0.65        60\n",
      "  Donald Rumsfeld       0.76      0.59      0.67        27\n",
      "    George W Bush       0.77      0.86      0.82       146\n",
      "Gerhard Schroeder       0.67      0.32      0.43        25\n",
      "      Hugo Chavez       0.69      0.60      0.64        15\n",
      "       Tony Blair       0.60      0.67      0.63        36\n",
      "\n",
      "      avg / total       0.72      0.72      0.71       322\n",
      "\n",
      "[[  9   1   0   3   0   0   0]\n",
      " [  0  40   3   9   3   0   5]\n",
      " [  0   2  16   9   0   0   0]\n",
      " [  0  11   1 126   1   1   6]\n",
      " [  0   4   0   6   8   2   5]\n",
      " [  0   2   1   3   0   9   0]\n",
      " [  0   4   0   7   0   1  24]]\n",
      "================================================\n",
      "Predição classificador LinearDiscriminantAnalysis\n",
      "================================================\n",
      "done in 0.000s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.67      0.92      0.77        13\n",
      "     Colin Powell       0.77      0.78      0.78        60\n",
      "  Donald Rumsfeld       0.81      0.63      0.71        27\n",
      "    George W Bush       0.88      0.89      0.88       146\n",
      "Gerhard Schroeder       0.70      0.76      0.73        25\n",
      "      Hugo Chavez       0.73      0.73      0.73        15\n",
      "       Tony Blair       0.69      0.61      0.65        36\n",
      "\n",
      "      avg / total       0.80      0.80      0.80       322\n",
      "\n",
      "[[ 12   1   0   0   0   0   0]\n",
      " [  3  47   1   6   0   2   1]\n",
      " [  1   2  17   5   1   1   0]\n",
      " [  2   6   2 130   1   0   5]\n",
      " [  0   1   1   1  19   0   3]\n",
      " [  0   2   0   0   1  11   1]\n",
      " [  0   2   0   6   5   1  22]]\n",
      "================================================\n",
      "Predição classificador SVC\n",
      "================================================\n",
      "done in 0.037s\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.80      0.92      0.86        13\n",
      "     Colin Powell       0.79      0.88      0.83        60\n",
      "  Donald Rumsfeld       0.79      0.85      0.82        27\n",
      "    George W Bush       0.90      0.91      0.91       146\n",
      "Gerhard Schroeder       0.86      0.72      0.78        25\n",
      "      Hugo Chavez       0.92      0.73      0.81        15\n",
      "       Tony Blair       0.90      0.78      0.84        36\n",
      "\n",
      "      avg / total       0.87      0.86      0.86       322\n",
      "\n",
      "[[ 12   1   0   0   0   0   0]\n",
      " [  1  53   0   4   0   1   1]\n",
      " [  0   2  23   2   0   0   0]\n",
      " [  2   8   3 133   0   0   0]\n",
      " [  0   1   2   2  18   0   2]\n",
      " [  0   2   0   1   1  11   0]\n",
      " [  0   0   1   5   2   0  28]]\n",
      "bestNC:\n",
      "[45, 75, 80, 75, 85]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[45, 75, 80, 75, 85]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_classifiersPCA(classifiers, train, test):\n",
    "    \n",
    "    print(len(classifiers))\n",
    "    bestNC = []\n",
    "    print(\"================================================\")\n",
    "    print(\"medindo componentes\")\n",
    "    print(\"================================================\")\n",
    "    #mede o melhor numero de componentes de cada classificador\n",
    "    for clf in classifiers: \n",
    "        #n componentes\n",
    "        n_components_array=[20, 30, 45, 55, 65,75,80,85,100]\n",
    "        score_array = np.zeros(len(n_components_array))\n",
    "        i=0\n",
    "\n",
    "        # Mede o melhor numero de componentes\n",
    "        for n_components in n_components_array:\n",
    "            pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(train)\n",
    "            \n",
    "            transformTrain = pca.transform(train)\n",
    "            transformTest = pca.transform(test)\n",
    "            \n",
    "            clf.fit(transformTrain, y_train)\n",
    "            #mede seu score\n",
    "            score_array[i] = clf.score(transformTest, y_test)\n",
    "            i=i+1\n",
    "        #seleciona o melhor numero de componentes dentre as opcoes\n",
    "        bestNC.append(n_components_array[score_array.argmax(axis=0)])        \n",
    "        \n",
    "    print(\"================================================\")\n",
    "    print(\"treinando classificadores\")\n",
    "    print(\"================================================\")\n",
    "    #treina os classificadores com os valores encontrados\n",
    "    for idx, clf in enumerate(classifiers):\n",
    "        #roda o PCA\n",
    "        pca = PCA(n_components=bestNC[idx], svd_solver='randomized', whiten=True).fit(train)\n",
    "        #treina o classificador\n",
    "        transformTrain = pca.transform(train)\n",
    "        transformTest = pca.transform(test)\n",
    "        \n",
    "        clf.fit(transformTrain, y_train)\n",
    "        \n",
    "        #prediz\n",
    "        print(\"================================================\")\n",
    "        #plt.xlabel(\"Predição classificador \" + clf.__class__.__name__, size=20)\n",
    "        print(\"Predição classificador \" + clf.__class__.__name__)\n",
    "        print(\"================================================\")\n",
    "        \n",
    "        t0 = time()\n",
    "        y_pred = clf.predict(transformTest)\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        print(confusion_matrix(y_test, y_pred, labels=range(n_classes)))\n",
    "            \n",
    "\n",
    "    print(\"bestNC:\")\n",
    "    print(bestNC)        \n",
    "    return bestNC\n",
    "\n",
    "train_classifiersPCA(clfss, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variancePCA(train, target):\n",
    "    \n",
    "    pca = PCA(n_components=train.shape[1])\n",
    "    pca.fit(train)\n",
    "        \n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.axes([.2, .2, .7, .7])\n",
    "    plt.plot(np.cumsum(pca.explained_variance_), linewidth=2)\n",
    "    \n",
    "    plt.axis('tight')\n",
    "    plt.xlabel('n_components')\n",
    "    plt.ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Qualitative evaluation of the predictions using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)\n",
    "        plt.title(titles[i], size=12)\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "\n",
    "\n",
    "# plot the result of the prediction on a portion of the test set\n",
    "\n",
    "def title(y_pred, y_test, target_names, i):\n",
    "    pred_name = target_names[y_pred[i]].rsplit(' ', 1)[-1]\n",
    "    true_name = target_names[y_test[i]].rsplit(' ', 1)[-1]\n",
    "    return 'predicted: %s\\ntrue:      %s' % (pred_name, true_name)\n",
    "\n",
    "#prediction_titles = [title(y_pred, y_test, target_names, i)\n",
    "#                     for i in range(y_pred.shape[0])]\n",
    "\n",
    "#plot_gallery(X_test, prediction_titles, h, w)\n",
    "\n",
    "# plot the gallery of the most significative eigenfaces\n",
    "\n",
    "#eigenface_titles = [\"eigenface %d\" % i for i in range(eigenfaces.shape[0])]\n",
    "#plot_gallery(eigenfaces, eigenface_titles, h, w)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyzeFeaturesLDA(train, target, lda):\n",
    "    \n",
    "    # Taking in as second argument the Target as labels\n",
    "    lda = LDA(n_components=2)\n",
    "    transform = lda.fit_transform(train, target)\n",
    "    \n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.scatter(transform[:,0],transform[:,1], s=20, c = target, cmap = \"nipy_spectral\", edgecolor = \"None\")\n",
    "    plt.colorbar()\n",
    "    plt.clim(0,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
